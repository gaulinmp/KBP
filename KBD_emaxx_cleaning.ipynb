{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gaulinmp/Dropbox/Documents/School/Projects/KBP_katrina_bond_to_private/data/emaxx/txt_files\n"
     ]
    }
   ],
   "source": [
    "cd /home/gaulinmp/Dropbox/Documents/School/Projects/KBP_katrina_bond_to_private/data/emaxx/txt_files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cd /mnt/storage/data/emaxx/txt_files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython: 3.0.0\n",
      "Numpy: 1.9.2\n",
      "Scipy: 0.15.1\n",
      "Pandas: 0.15.2\n",
      "SQLalchemy: 0.9.9\n",
      "MatPlotLib: 1.4.3\n",
      "Statsmodels: 0.6.1\n"
     ]
    }
   ],
   "source": [
    "# system/os/regex and basic math functions\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from itertools import combinations as npn\n",
    " \n",
    "# IPython display convenience stuff\n",
    "from IPython.display import display_html, display_javascript\n",
    "from IPython import __version__ as ipythonversion\n",
    "print(\"IPython: {}\".format(ipythonversion))\n",
    "    \n",
    "# Set logging level\n",
    "import logging\n",
    "logging.getLogger(\"\").setLevel(logging.DEBUG)\n",
    " \n",
    "# numpy for matrix algebra\n",
    "import numpy as np\n",
    "print(\"Numpy: {}\".format(np.version.full_version))\n",
    " \n",
    "# scipy for probability distributions and some statistical tests\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "print(\"Scipy: {}\".format(sp.version.full_version))\n",
    " \n",
    "# pandas for data manipulation\n",
    "import pandas as pd\n",
    "print(\"Pandas: {}\".format(pd.version.version))\n",
    " \n",
    "# Set pandas display options for pretty pretty printing\n",
    "pd.set_option('html', True, 'precision', 8)\n",
    "pd.set_option('max_rows',200,'max_columns',50)\n",
    " \n",
    "# pandas web interface for things like FF factors\n",
    "import pandas.io.data as web\n",
    " \n",
    "# pytables for hdf5 library (on-disk storage)\n",
    "# import tables as tb\n",
    " \n",
    "# SQLAlchemy for relational db management\n",
    "import sqlalchemy as sa\n",
    "print(\"SQLalchemy: {}\".format(sa.__version__))\n",
    "\n",
    "# matplotlib for plotting and pyplot for MATLAB-style API\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"MatPlotLib: {}\".format(mpl.__version__))\n",
    " \n",
    "# display plots inline\n",
    "%matplotlib inline\n",
    " \n",
    "# statsmodels for models with a formula framework similar to R \n",
    "import statsmodels.api as sm\n",
    "print(\"Statsmodels: {}\".format(sm.version.full_version))\n",
    " \n",
    "# datetime for date functions/time series\n",
    "import datetime as dt\n",
    "import dateutil\n",
    "\n",
    "from collections import defaultdict as ddict\n",
    "\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get file names and count across year/qtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zulu = ddict(int)\n",
    "for r,d,f in os.walk('.'):\n",
    "    if not f: continue\n",
    "    for fname in f: zulu[fname] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check filesizes to find which are same across years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BCRSECTS.TXT', 'NONCALL.TXT', 'ENTITY.TXT', 'ASSETCLM.TXT', 'BONDCAT.TXT', 'FIRMTYPE.TXT', 'SECURED.TXT', 'CORPCRED.TXT', 'CPNSTRU.TXT', 'CORPCALL.TXT', 'STATE.TXT', 'NCREDTYP.TXT', 'REDEMETH.TXT']\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(index=zulu.keys())\n",
    "\n",
    "for r,d,f in os.walk('.'):\n",
    "    if d: continue\n",
    "    #print(r,d,f)\n",
    "    yr,qtr = re.search(r\"(20\\d\\d)_Q(\\d)\", r).groups()\n",
    "    \n",
    "    data['{}_{}'.format(yr,qtr)\n",
    "         ] = pd.Series({fn:os.stat(os.path.join(r,fn)).st_size for fn in f})\n",
    "\n",
    "samesame = [poo\n",
    "            for poo in data.index\n",
    "            if data.transpose()[poo].max()==data.transpose()[poo].min()]\n",
    "print(samesame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test SAME SAME\n",
    "\n",
    "This below runs to verify that all the files that have the same content, not just the same filesize. Run once to check, then ignore FOREVER!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txts = {}\n",
    "for r,d,f in os.walk('.'):\n",
    "    if not f: continue\n",
    "    for fname in f:\n",
    "        if fname not in samesame: continue\n",
    "        if fname not in txts:\n",
    "            with open(os.path.join(r,fname)) as fh:\n",
    "                txts[fname] = fh.read()\n",
    "        with open(os.path.join(r,fname)) as fh:\n",
    "            if txts[fname] == fh.read(): continue\n",
    "        print(\"NOT SAME SAME!\", fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make function that walks directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def walk_files(root=None):\n",
    "    \"\"\"Returns tuple (root,fname,yr,qtr)\"\"\"\n",
    "    if not root: root=\".\"\n",
    "    vals = []\n",
    "    for r,d,f in os.walk(root):\n",
    "        if d: continue\n",
    "        try:\n",
    "            yr,qtr = re.search(r\"(20\\d\\d)_Q(\\d)\", r).groups()\n",
    "        except AttributeError as e:\n",
    "            print(r)\n",
    "            continue\n",
    "            #raise e\n",
    "        for fname in f:\n",
    "            vals.append((r,fname,yr,qtr))\n",
    "    return sorted(vals,key=lambda x: \"{}_{}\".format(x[0],x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n"
     ]
    }
   ],
   "source": [
    "# Remove stupid \\x1a EOF marker.\n",
    "last_yr = ''\n",
    "for x in walk_files():\n",
    "    r,fname,yr,qtr = x\n",
    "    if yr != last_yr:\n",
    "        print(yr)\n",
    "        last_yr = yr\n",
    "    full_path = os.path.join(r,fname)\n",
    "    with open(full_path, encoding = \"ISO-8859-1\") as fh:\n",
    "        tmp = fh.read()\n",
    "    stripped_tmp = tmp.strip('\\r\\n \\x1a')  # remove b'\\x1a'\n",
    "    if '\\x1a' not in stripped_tmp:\n",
    "        continue\n",
    "    with open(full_path, 'w', encoding='utf-8') as fh:\n",
    "        fh.write(stripped_tmp.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up bad quotes in original files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUND.TXT 2000 3 727928 727929\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n Growth \"A\" Clas<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n Growth 'A' Clas"
      ],
      "text/plain": [
       "<IPython.core.display.HTML at 0x7fc4c8075390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bad_quote_re = r'(?<![,\\n])\"(?![,\\n])'\n",
    "for x in walk_files():\n",
    "    r,fname,yr,qtr = x\n",
    "    if int(yr) > 2001: break\n",
    "    if fname not in column_headings.keys(): continue\n",
    "    with open(os.path.join(r,fname), encoding=\"ISO-8859-1\") as fh:\n",
    "        grr = fh.read()\n",
    "        rslts = re.search(bad_quote_re,grr[1:])\n",
    "        if rslts: # find any \" not preceded by a comma\n",
    "            newgrr = re.sub(bad_quote_re, \"'\", grr)\n",
    "            print(fname,yr,qtr,rslts.start(),rslts.end())\n",
    "            display(HTML(\"{0}{1}<br>{0}{2}\".format('&nbsp;'*10,\n",
    "                                                   grr[rslts.start()-8:rslts.end()+8],\n",
    "                                                   newgrr[rslts.start()-8:rslts.end()+8])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def strip_dot_zero(csv_string):\n",
    "    \"\"\"Pandas prints out 1.0 for all floats, and \n",
    "    telling it what are ints is annoying.\"\"\"\n",
    "\n",
    "    return re.sub(r'[.]0(?=[,\\n])', \"\", csv_string).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Headings\n",
    "\n",
    "ISSUERS.TXT: cusip6, name, name_sort, credit_sector, country, nothing, entity, state, ticker\n",
    "\n",
    "SECMAST.TXT: cusip6, cusip78, issue_desc, coupon_rate, coupon_structure, currency_code, maturity_year, maturity_date, market_sector, collateral_code, cusip_source, private, issue_amt_outstanding, issue_amt_change, num_held, num_buying, num_selling, total_par_held, pledge_code, issue_date, moody, s_and_p, fitch, duff_and_phelps\n",
    "\n",
    "FUND.TXT: sub_account_id, sub_account_class, sub_account_name, sub_account_name_sort, market_sector, managing_firm_id, sub_account_country, total_par_amt_held, total_number_bonds_held, update_date, trash\n",
    "\n",
    "HOLDING.TXT: cusip6, cusip78, sub_account_id, par_amount, report_date, par_amount_change, managing_firm_id, acquisition_book_value\n",
    "\n",
    "FIRM.TXT: managing_firm_id, managing_firm_name, managing_firm_name_sort, managing_firm_phone, managing_firm_fax, managing_firm_loc_addr1, managing_firm_loc_addr2, managing_firm_loc_city, managing_firm_loc_state, managing_firm_loc_zip, managing_firm_mailing_addr1, managing_firm_mailing_addr2, managing_firm_mailing_city, managing_firm_mailing_state, managing_firm_mailing_zip, managing_firm_type, managing_firm_country_code, managing_firm_phone_country_code, managing_firm_total_par_held, managing_firm_number_issues_held"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_str = \"\"\"\n",
    "ISSUERS.TXT: cusip6, name, name_sort, credit_sector, country, nothing, entity, state, ticker\n",
    "SECMAST.TXT: cusip6, cusip78, issue_desc, coupon_rate, coupon_structure, currency_code, maturity_year, maturity_date, market_sector, collateral_code, cusip_source, private, issue_amt_outstanding, issue_amt_change, num_held, num_buying, num_selling, total_par_held, pledge_code, issue_date, moody, s_and_p, fitch, duff_and_phelps\n",
    "FUND.TXT: sub_account_id, sub_account_class, sub_account_name, sub_account_name_sort, market_sector, managing_firm_id, sub_account_country, total_par_amt_held, total_number_bonds_held, update_date, _\n",
    "HOLDING.TXT: cusip6, cusip78, sub_account_id, par_amount, report_date, par_amount_change, managing_firm_id, acquisition_book_value\n",
    "FIRM.TXT: managing_firm_id, managing_firm_name, managing_firm_name_sort, managing_firm_phone, managing_firm_fax, managing_firm_loc_addr1, managing_firm_loc_addr2, managing_firm_loc_city, managing_firm_loc_state, managing_firm_loc_zip, managing_firm_mailing_addr1, managing_firm_mailing_addr2, managing_firm_mailing_city, managing_firm_mailing_state, managing_firm_mailing_zip, managing_firm_type, managing_firm_country_code, managing_firm_phone_country_code, managing_firm_total_par_held, managing_firm_number_issues_held\n",
    "\"\"\".strip().split('\\n')\n",
    "\n",
    "column_headings = {ln.split(': ')[0]:ln.split(': ')[1].split(', ') for ln in col_str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# . denotes numeric\n",
    "keep_col_str = \"\"\"\n",
    "ISSUERS.TXT: cusip6, year., quarter., name, name_sort, country, ticker\n",
    "SECMAST.TXT: cusip6, cusip78, year., quarter., issue_desc, coupon_rate, coupon_structure, currency_code, maturity_year., maturity_date, market_sector, collateral_code, cusip_source, private, issue_amt_outstanding., issue_amt_change., num_held., num_buying., num_selling., total_par_held., pledge_code, issue_date, moody, s_and_p, fitch, duff_and_phelps\n",
    "FUND.TXT: sub_account_id., year., quarter., sub_account_class, sub_account_name, sub_account_name_sort, managing_firm_id., sub_account_country, total_par_amt_held., total_number_bonds_held., update_date\n",
    "HOLDING.TXT: cusip6, cusip78, year., quarter., sub_account_id., par_amount., report_date, par_amount_change., managing_firm_id., acquisition_book_value.\n",
    "FIRM.TXT: managing_firm_id., year., quarter., managing_firm_name, managing_firm_name_sort, managing_firm_type, managing_firm_country_code, managing_firm_total_par_held., managing_firm_number_issues_held.\n",
    "\"\"\".strip().split('\\n')\n",
    "\n",
    "keep_cols = {ln.split(': ')[0]:ln.split(': ')[1].split(', ') for ln in keep_col_str}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do all the files that are simple.\n",
    "Ignores SECMAST, HOLDING, and FUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_account_id,year,quarter,sub_account_class,sub_account_name,sub_account_name_sort,managing_firm_id,sub_account_country,total_par_amt_held,total_number_bonds_held,update_date\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 FUND.TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./2000_Q1/Q1 FIRM.TXT 2000 1\n",
      "FIRM.TXT managing_firm_id,year,quarter,managing_firm_name,managing_firm_name_sort,managing_firm_type,managing_firm_country_code,managing_firm_total_par_held,managing_firm_number_issues_held\n",
      "FUND.TXT sub_account_id,year,quarter,sub_account_class,sub_account_name,sub_account_name_sort,managing_firm_id,sub_account_country,total_par_amt_held,total_number_bonds_held,update_date\n",
      "HOLDING.TXT cusip6,cusip78,year,quarter,sub_account_id,par_amount,report_date,par_amount_change,managing_firm_id,acquisition_book_value\n",
      "ISSUERS.TXT cusip6,year,quarter,name,name_sort,country,ticker\n",
      "SECMAST.TXT cusip6,cusip78,year,quarter,issue_desc,coupon_rate,coupon_structure,currency_code,maturity_year,maturity_date,market_sector,collateral_code,cusip_source,private,issue_amt_outstanding,issue_amt_change,num_held,num_buying,num_selling,total_par_held,pledge_code,issue_date,moody,s_and_p,fitch,duff_and_phelps\n",
      "./2001_Q1/Q1 FIRM.TXT 2001 1\n",
      "./2002_Q1/Q1 FIRM.TXT 2002 1\n",
      "./2003_Q1/Q1 FIRM.TXT 2003 1\n",
      "./2004_Q1/Q1 FIRM.TXT 2004 1\n",
      "./2005_Q1/Q1 FIRM.TXT 2005 1\n",
      "./2006_Q1/Q1 FIRM.TXT 2006 1\n",
      "./2007_Q1/Q1 FIRM.TXT 2007 1\n",
      "./2008_Q1/Q1 FIRM.TXT 2008 1\n",
      "./2009_Q1/Q1 FIRM.TXT 2009 1\n",
      "./2010_Q1/Q1 FIRM.TXT 2010 1\n",
      "./2011_Q1/Q1 FIRM.TXT 2011 1\n",
      "./2012_Q1/Q1 FIRM.TXT 2012 1\n",
      "./2013_Q1/Q1 FIRM.TXT 2013 1\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    raise\n",
    "    \n",
    "for r,fname,yr,qtr in walk_files():\n",
    "    first = yr+qtr=='20001'\n",
    "    if fname not in column_headings.keys():\n",
    "        continue\n",
    "    #if fname in ('SECMAST.TXT', 'HOLDING.TXT'): continue\n",
    "    if yr != oldyr:\n",
    "        print(r,fname,yr,qtr)\n",
    "        oldyr = yr\n",
    "    new_data = pd.read_csv(os.path.join(r,fname), names=column_headings[fname]\n",
    "                           ,dtype=None if fname != 'SECMAST.TXT' else {'duff_and_phelps':pd.np.object}\n",
    "                           ,header=None, index_col=False, low_memory=False)\n",
    "    \n",
    "    if fname == 'HOLDING.TXT':\n",
    "        new_data[column_headings[fname][2:]] = new_data[column_headings[fname][2:]\n",
    "                                                       ].convert_objects(convert_numeric=True)\n",
    "    if fname in ('FIRM.TXT', 'HOLDING.TXT', 'FUND.TXT'):\n",
    "        new_data['managing_firm_id'] = new_data.managing_firm_id.apply(lambda x: -99 if x == 'CO-MANAGED' else x)\n",
    "    \n",
    "    new_data['year'], new_data['quarter'] = yr,qtr\n",
    "    \n",
    "    new_txt = new_data[[x.strip('.') for x in keep_cols[fname]]\n",
    "                      ].to_csv(header=first, index=False, encoding=\"utf-8\")\n",
    "    if first: print(fname,new_txt.split('\\n')[0])\n",
    "    with open(os.path.join(fname), 'a' if not first else 'w', encoding=\"utf-8\") as fh:\n",
    "        if not first: fh.write(\"\\n\")\n",
    "        fh.write(strip_dot_zero(new_txt).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add to postgres server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def type_formatter(name):\n",
    "    if '.' in name:\n",
    "        return \"{} integer DEFAULT 0\".format(name.split('.')[0])\n",
    "    return \"{} text\".format(name)\n",
    "    \n",
    "def make_psql_create_string(fname, col_dict):\n",
    "    name = fname.split('.')[0].lower()\n",
    "    return \"\"\"\n",
    "    CREATE TABLE \"{}\" ({})\n",
    "    WITH ( OIDS=FALSE );\n",
    "    \"\"\".format(name\n",
    "               ,\",\\n\\t\".join([type_formatter(col) for col in col_dict[fname]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\COPY fund FROM '/home/gaulinmp/Dropbox/Documents/School/Projects/KBP_katrina_bond_to_private/data/emaxx/txt_files/FUND.TXT' WITH CSV HEADER;\n",
      "\\COPY issuers FROM '/home/gaulinmp/Dropbox/Documents/School/Projects/KBP_katrina_bond_to_private/data/emaxx/txt_files/ISSUERS.TXT' WITH CSV HEADER;\n",
      "\\COPY holding FROM '/home/gaulinmp/Dropbox/Documents/School/Projects/KBP_katrina_bond_to_private/data/emaxx/txt_files/HOLDING.TXT' WITH CSV HEADER;\n",
      "\\COPY firm FROM '/home/gaulinmp/Dropbox/Documents/School/Projects/KBP_katrina_bond_to_private/data/emaxx/txt_files/FIRM.TXT' WITH CSV HEADER;\n",
      "\\COPY secmast FROM '/home/gaulinmp/Dropbox/Documents/School/Projects/KBP_katrina_bond_to_private/data/emaxx/txt_files/SECMAST.TXT' WITH CSV HEADER;\n"
     ]
    }
   ],
   "source": [
    "ROOTDIR = '/home/gaulinmp/Dropbox/Documents/School/Projects/KBP_katrina_bond_to_private/data/emaxx/txt_files/'\n",
    "if False:\n",
    "    engine = sa.create_engine('postgresql+psycopg2:///kbd?host=/var/run/postgresql')\n",
    "    for fname,cols in column_headings.items():\n",
    "        tmp_name = fname.split('.')[0].lower()\n",
    "        with engine.connect() as connection:\n",
    "            connection.execute(\"DROP TABLE IF EXISTS {};\".format(tmp_name))\n",
    "            query = make_psql_create_string(fname, keep_cols)\n",
    "            connection.execute(query)\n",
    "        #with engine_create.connect() as connection:\n",
    "            query = \"COPY {0} FROM '{1}' WITH CSV HEADER;\".format(\n",
    "                        tmp_name, os.path.join(ROOTDIR, fname))\n",
    "            print('\\\\'+query)\n",
    "            #results = connection.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
